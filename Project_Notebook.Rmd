---
title: "Time Series Analysis"
author: "Ramnath K (22BM6JP38), Vaibhav Goyal (22BM6JP54)"
date: "`r Sys.Date()`"
abstract: "This a project as part of our course Stochastic Process and Application at ISI, Kolkata. We will be analysing the time series data of new cars sales in USA from January 1992 to October 2022. The end goal of the project would be to be able to fit a suitable time series model and predict values for certain period. The repository for this project can be found at https://github.com/vai-b-hav/SPA_Project"
knit: (function(inputFile, encoding) {
      out_dir <- "Report";
      rmarkdown::render(inputFile,
                        encoding=encoding,
                        output_dir=file.path(dirname(inputFile), out_dir))})
output: word_document
---

---
# Data is fetched from the Data subfolder.
# Knitted Output of the notebook will be stored in the Report subfolder.
---

***

# Initial Setup

#### Import Libraries:

We need to import the following libraries for the project:

1.  *astsa* - for Time Series Analysis
2.  *readxl* - for importing data from Excel file

```{r lib import}
library(astsa)
library(readxl)
```

```{r output setup, include=FALSE}
# Flextable imported to create tables in output file
library(flextable)
# Table caption set to bottom
knitr::opts_chunk$set(tab.topcaption = FALSE)
# Avoid scientific notations in the plots
options(scipen = 999)
```


#### Import Data
```{r data import}
data <- read_xlsx("./Data/US_MRTR.xlsx", sheet = 'Sales')
```
```{r table code, echo=FALSE}
ft <- 
  flextable(head(data)) |>
  set_table_properties(layout = "autofit") |>
  set_caption(caption = "Sample from data") |>
  colformat_num(j = 'Year', big.mark = "")
ft
```

Before proceeding, let us perform some minor transformations:

1.  Change name of the sales column for easier reference.
2.  Change unit of the sales from Millions to Billions.

```{r data tansform}
colnames(data)[3] <- 'Sales'
data$Sales <- data$Sales / 1000 # Change scale from Millions to Billions
```

```{r table_2 code, echo=FALSE}
ft <- 
  flextable(head(data)) |>
  set_table_properties(layout = "autofit") |>
  set_caption(caption = "Sample from data after transformations") |>
  colformat_num(j = 'Year', big.mark = "")
ft
```

# Analysis

#### Define time series

The *ts()* function from the *astsa* helps us define an indexed time series from out sales data.

Sometimes when plotting the data, it is helpful to have the actual time intervals on the on the axis, for this purpose we also create a time series indexed by the time intervals *(sales.ts in the below code)*.
```{r ts}
sales <- ts(data = data$Sales)
sales.ts <- ts(data = data$Sales, frequency = 12, start = c(1992,1))
```
#### Plot time series
```{r plot, echo=FALSE, fig.width=9, fig.height=6}
plot(sales.ts, type="o", pch = 20, ylab = "Sales (in $ 'B)", main = "Monthly New Car Sales in US [Jan 1992 - Oct 2022]")
rect(xleft=2008,xright = 2010, ybottom = par("usr")[3], ytop=par("usr")[4], density=10, col = "red")
rect(xleft=2020,xright = 2021, ybottom = par("usr")[3], ytop=par("usr")[4], density=10, col = "blue")

```

On plotting the time series data, we observe a clear increasing trend and a seasonality in the data.

We observe a departure from the general trend for the years 2008 to 2010 which may be attributed to the global economic crisis of 2008. *(Highlighted in red region in the above plot)*

We also observe a sharp drop in the sales in the years 2020 to 2021 which can be attributed to the CoVID-19 pandemic. *(Highlighted in blue region in the above plot)*

For our initial initial analysis, we will ignore these two anomalies and proceed with the data as is.

## AR(1) Model

Since there is upward trend, we first need to make it stationary to fit an AR(1) model. To create a (possibly) stationary series, weâ€™ll examine the first differences $y_t = x_t - x_{t-1}$.

```{r}
sales.diff <- diff(sales, 1)
```

The time series plot of the first differences is as follows:

```{r, echo=FALSE, fig.width=9, fig.height=6}
plot(sales.diff, type="o", pch = 20,
     ylab = expression("Sales"["t"]~-~"Sales"["t-1"]),
     xlab = "Index",
     main = "Time Series Plot of Sales Differences")
```

And, the following plot is the sample estimate of the autocorrelation function of 1st differences:

```{r, echo=FALSE, fig.width=9, fig.height=6}
acf(sales.diff,xlim=c(1,24))
```

In the ACF plot we observe that there are multiple lag values that have significant ACFs. Thus an AR(1) model will not be a suitable choice for this data.

If we still consider having a look at the plots of the AR(1) model, they would be as follows:

```{r, echo=FALSE, fig.width=9, fig.height=5}
sales.diff.lag1 <- lag(sales.diff,-1)
y <- cbind(sales.diff,sales.diff.lag1)
ar1.sales.diff <- lm(y[,1] ~ y[,2])
par(mfrow=c(1,3))
plot(y[,2], y[,1],
     main = 'AR(1) of Sales Differences',
     xlab = "Sales Differnce (t-1)",
     ylab = "Sales Differnce (t)")
abline(ar1.sales.diff, col = 'red')
plot(ar1.sales.diff$fit,ar1.sales.diff$residuals,
     main = 'Residual Plot',
     xlab = 'Fitted Value',
     ylab = 'Residual')
acf(ar1.sales.diff$residuals, xlim = c(1,24), main = '')
title(main = 'ACF of Residuals', line = 0.5)
```

From the first scatter plot and the residual plot, we can clearly see that AR(1) model is not a good fit. Also, from the ACF plot, it is evident that the residuals still have significant auto-correlation.  

## SARIMA Model

Since we have a monthly data that exhibits seasonality, we should first observe the plot for -
$${Z_{t} = \nabla_{12}x_{t} = x_t - x_{t-12}}$$
The idea is that differences from the previous year may be, on average, about the same for each month of a year.

```{r}
sales.diff.12 <- diff(sales, 12)
```


```{r, echo=FALSE, fig.width=9, fig.height=6}
plot(sales.diff.12, type = 'o', pch = 20,
     ylab = expression("Sales"["t"]~-~"Sales"["t-12"]),
     xlab = 'Index',
     main = "Time Series Plot of Sales Differences")
```

Here we see that the data has been de-trended, thus, further differencing is not necessary.

Since we have kept the data of 2008 economic crisis as well as the CoVID-19 pandemic, we see there are a lot of outliers in the plot. We will still try to fit a SARIMA model. For the identification of the SARIMA model, we need to have a look at the ACF and PACF plot of the detrended series. 

```{r ,results='hide',fig.width=9, fig.height=6}
acf2(sales.diff.12,48)
```
Based on this let us try to 

```{r}
sales.sarima <- sarima(sales, 2,0,0,0,1,1,12)

sales.sarima$ttable
```

```{r}
trial <- ts(data$Sales[217:337])
#trial <- ts(data$Sales[1:193])
plot(trial)
trial.diff.12 <- diff(trial, 12)
plot(trial.diff.12)
trial.diff.12.1 <- diff(trial.diff.12, 1)
plot(trial.diff.12.1)
acf2(trial.diff.12.1, 48)
#sarima(trial, 0,0,1,1,1,0,12)
sarima(trial, 0,1,1,0,1,0,12)
```


```{r, fig.width=30, fig.height=10}
# sarima.for(trial, 24, 0,1,1,0,1,1,12)
trial.ts <- ts(data = data$Sales[217:337], frequency = 12, start = c(2010,1))
trial2.ts <- ts(data = data$Sales[217:312], frequency = 12, start = c(2010,1))
trial3.ts <- ts(data = data$Sales[313:337], frequency = 12, start = c(2018,1))
sarima.for(trial2.ts, 25,0,1,1,0,1,0,12)
lines(trial3.ts, lty = 2, col = 'blue')
```



